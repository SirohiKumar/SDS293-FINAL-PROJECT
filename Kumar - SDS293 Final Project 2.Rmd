---
title: "Kumar - SDS293 Final Project 2"
output:
  pdf_document: default
---

## Part I: Loading and Cleaning the Data

Load libraries
```{r message=F}

library(ggplot2)
library(tidyverse)
library(randomForest)
library(stringr)
library(tree)
library(fs)

```

Load data on each member of the legislature - `people_csv`
```{r message=F}

## locate where all of the "people.csv"s are for all the different years
people_dir = "/Users/sirohikumar/Library/CloudStorage/GoogleDrive-sirohikumar185@gmail.com/My Drive/UNDERGRAD/2024-25 JUNIOR YEAR/2025 SDS 293 - MACHINE LEARNING/SDS293-FINAL-PROJECT/data/people_csv"

## list these csv files
people_files = fs::dir_ls(people_dir)

## load in all of the people.csvs, adding an id column with the years and creating a column for legislature
people_csv = people_files %>%
    map_dfr(read_csv, .id = "source") %>%
    mutate(year = substr(source, 186, 194),
           legislature = case_when(year == "2009-2010" ~ "124",
                           year == "2011-2012" ~ "125",
                           year == "2013-2014" ~ "126",
                           year == "2015-2016" ~ "127",
                           year == "2017-2018" ~ "128",
                           year == "2019-2020" ~ "129",
                           year == "2021-2022" ~ "130",
                           year == "2023-2024" ~ "131",
                           year == "2025-2026" ~ "132",)) %>%
    select(-source) %>%
    mutate(people_id = as.character(people_id),
       party_id = as.character(party_id),
       role_id = as.character(role_id),
       committee_id = as.character(committee_id),
       knowwho_pid = as.character(knowwho_pid)) %>%     ## convert ids to chrs
    select(-followthemoney_eid, -votesmart_id,          ## remove unnecessary columns
           -opensecrets_id, -knowwho_pid,
           -ballotpedia, -committee_id, -first_name, 
           -middle_name, -last_name, -suffix, -nickname,
           -role_id, -year, -party_id)                  ## remove redundant predictors

## filter out the wrong years because of redistricting
people_csv = people_csv %>%
    filter(legislature < 131 & legislature > 125) %>%
    mutate(legislature = as.character(legislature))

head(people_csv)

```

Load data on all bills from each Congress - `bills.csv`
```{r message=F}

## locate where all of the "bills.csv"s are for all the different years
bills_dir = "/Users/sirohikumar/Library/CloudStorage/GoogleDrive-sirohikumar185@gmail.com/My Drive/UNDERGRAD/2024-25 JUNIOR YEAR/2025 SDS 293 - MACHINE LEARNING/SDS293-FINAL-PROJECT/data/bills_csv"

## list these csv files
bills_files = fs::dir_ls(bills_dir)

## load in all of the bills csvs, adding an id column with the years and creating a column for legislature
bills_csv = bills_files %>%
    map_dfr(read_csv, .id = "source") %>%
    mutate(year = substr(source, 185, 193),
           legislature = case_when(year == "2009-2010" ~ "124",
                           year == "2011-2012" ~ "125",
                           year == "2013-2014" ~ "126",
                           year == "2015-2016" ~ "127",
                           year == "2017-2018" ~ "128",
                           year == "2019-2020" ~ "129",
                           year == "2021-2022" ~ "130",
                           year == "2023-2024" ~ "131",
                           year == "2025-2026" ~ "132",)) %>%
    select(-source) %>%
    mutate(bill_id = as.character(bill_id),
           status = as.character(status),
           committee_id = as.character(committee_id),
           legislature = as.numeric(legislature),
           session_id = as.character(session_id))           ## convert ids to chrs

## remove data from before 2013 and after 2022 because of redistricting every 10 years
bills_csv = bills_csv %>%
    filter(legislature < 131 & legislature > 125) %>%
    mutate(legislature = as.character(legislature))

head(bills_csv)

```

Determine who introduced each bill - `sponsors.csv` 
```{r message=F}

sponsors_dir = "/Users/sirohikumar/Library/CloudStorage/GoogleDrive-sirohikumar185@gmail.com/My Drive/UNDERGRAD/2024-25 JUNIOR YEAR/2025 SDS 293 - MACHINE LEARNING/SDS293-FINAL-PROJECT/data/sponsors_csv"

## list these csv files
sponsors_files = fs::dir_ls(sponsors_dir)

## load in all of the bills csvs, adding an id column with the years and creating a column for legislature
sponsors_csv = sponsors_files %>%
    map_dfr(read_csv, .id = "source") %>%
    mutate(year = substr(source, 188, 196),
           legislature = case_when(year == "2009-2010" ~ "124",
                           year == "2011-2012" ~ "125",
                           year == "2013-2014" ~ "126",
                           year == "2015-2016" ~ "127",
                           year == "2017-2018" ~ "128",
                           year == "2019-2020" ~ "129",
                           year == "2021-2022" ~ "130",
                           year == "2023-2024" ~ "131",
                           year == "2025-2026" ~ "132",)) %>%
    select(-source) %>%
    mutate(bill_id = as.character(bill_id),
           people_id = as.character(people_id),
           legislature = as.numeric(legislature),
           position = as.character(position))           ## convert ids to chrs

## similarly filter out the wrong years because of redistricting
sponsors_csv = sponsors_csv %>%
    filter(legislature < 131 & legislature > 125) %>%
    mutate(legislature = as.character(legislature))

head(sponsors_csv)

```

Add the primary sponsor (person who introduced the bills) to `bills_csv`. We will have to filter out bills where sponsorship data is unavailable.  
```{r}

## filter sponsors until we have the primary sponsor for each bill (aka who introduced it)
sponsors_csv = sponsors_csv %>% 
    filter(position == 1) 

## join the people_id column (primary sponsor id) to bills_csv by bill_id
bills_csv = bills_csv %>%
    left_join(sponsors_csv[,c("people_id","bill_id")], by = join_by(bill_id)) %>%
    
    ## remove bills without primary sponsors and without a current status
    filter(!is.na(people_id) & !is.na(status_desc))

## bills now contains the people_id of its sponsor
head(bills_csv)

```

There is some inconsistency between members' roles and districts if they moved between chambers. Filter out rows where the district doesn't align with the chamber the member resides in. Dataframe goes from 953 --> 905 rows. 
```{r}

## look at an example
people_csv %>%
    filter(people_id == 8815)

house_members = people_csv %>%
    filter(role == "Rep") %>%           ## filter members by their role
    filter(str_detect(district, '^H'))  ## remove any columns where senate districts are listed instead

senate_members = people_csv %>%
    filter(role == "Sen") %>%           ## filter down to senate members
    filter(str_detect(district, '^S'))  ## remove any columns where house districts are listed instead

## combine house and senate members back into people_csv
people_csv = rbind(senate_members, house_members)

## look at the example again
people_csv %>%
    filter(people_id == 8815)

```

## Part 2: Calculating efficacy of members

For each member during each legislature, determine the number of their bills at each status a bill can be at: Passed, Failed, Introduced, etc. These are exclusive labels - no bill is in two categories. 
```{r}

## isolate the number of bills at each status and then pivot wider
scores = bills_csv %>%
    group_by(people_id, legislature, status_desc) %>%
    summarise(bill_count = n(), .groups = "drop") %>%
    pivot_wider(names_from = status_desc,
                values_from = bill_count,
                values_fill = list(bill_count = 0)) %>%
    group_by(people_id, legislature)%>%
    ungroup()

## right join because we filtered out some people earlier with mismatched districts/roles
people_csv = scores %>%
  right_join(people_csv, by = c("people_id", "legislature"))

## there are some people who didn't introduce any legislation during some terms, which have NAs for their status_desc columns (Passed, Failed, etc). Fill with zeros. 
people_csv = people_csv %>%
    mutate_at(vars(Failed, Passed, Engrossed, Enrolled, Introduced, Vetoed), 
              ~replace_na(., 0))

head(people_csv)

```

Clean the data again, making sure all columns are the correct data type. 
```{r}

## turn several into factors (party_id, district, role, etc)
people_csv = people_csv %>%
    mutate(district = as.factor(district),
           party = as.factor(party),
           role = as.factor(role),
           legislature = as.factor(legislature),
           Passed = as.numeric(Passed))

## filter some people ran unenrolled, mark them independents
people_csv = people_csv %>%
    mutate_at(vars(party), ~replace_na(., "I"))

## make districts into a numerical predictor by taking right 3 characters of district
people_csv = people_csv %>%
    filter(district != "HD-TRIBE") %>%
    mutate(district = as.numeric(str_sub(district, start = -3)))

head(people_csv)

```

## Part 3: Exploratory Analysis

Examine the co-linearity between the numeric predictors
```{r}

num_preds = people_csv %>%
    select(district, Passed, Failed, Engrossed, Enrolled, Vetoed, Introduced) %>%
    as.data.frame()
    
# Compute the correlation matrix
cor_matrix <- cor(num_preds)

# Visualize the correlation matrix
corrplot::corrplot(cor_matrix, method = "circle")

```

## Part 4: Random Forest

Predicting someone's efficacy (in the form of bills passed) as a function of all possible predictors using random forest: 
```{r}

set.seed(1)

## split for test/training data
train = people_csv %>%
    group_by(people_id) %>%
    summarize(people_id = unique(people_id))

## training data is 80% of total data
train = train %>% sample_frac(0.8) 
train = dplyr::right_join(people_csv, train, by = 'people_id')
test = dplyr::anti_join(people_csv, train, by = 'people_id')

head(train)

```

Random forest is done using `randomForest()`, where `mtry` is the number of variables considered at each split. We will also optimize m, and find that OOB error is lowest at `m = 2`. 
```{r}

rf.maine = randomForest(Passed ~ ., data = train, mtry = 3,
                         importance = T)

oob.values = vector(length = 10)

for (i in 1:10) {
    temp.model = randomForest(Passed ~ ., data = train,
                              mtry = i, ntree = 500)
    oob.values[i] = temp.model$mse[length(temp.model$mse)]
}

oob.values

```

Recreate the model where `m = 2`: 
```{r}

rf.maine = randomForest(Passed ~ ., data = train, mtry = 2,
                         importance = T)

rf.maine

```

Visualize the error as a function of the number of trees. As increasing the number of trees doesn't lead to over-fitting, We can use this default high number of trees (500).
```{r}

plot(rf.maine)

```

We can visualize the accuracy of the model on the training data: 
```{r}

plot(predict(rf.maine), train$Passed, 
     xlab = "Predicted", ylab = "Actual")
abline(0, 1)

```

Calculate test MSE using optimized model
```{r}

maine.test = test[, "Passed"]
yhat.rf = as.data.frame(predict(rf.maine, newdata = test))

cbind(maine.test, yhat.rf) %>%
    mutate(diff = Passed - `predict(rf.maine, newdata = test)`,
           squared = diff^2) %>%
    summarize(testMSE = mean(squared))

```

We can use `importance()` to view the influence of each node on two parameters: 
```{r}

importance(rf.maine)

```

We can visualize these importance measures using `varImpPlot()`
```{r}

varImpPlot(rf.maine)

```

Visualize the effects of the most influential variables on `%IncMSE` and `IncNodePurity`: 
```{r}

partialPlot(rf.maine, train %>% as.data.frame(), "role")
partialPlot(rf.maine, train %>% as.data.frame(), "Introduced")

```